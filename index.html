<!DOCTYPE html>
<html lang="en">
<head>
    <title>Yixin Liu</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Yixin Liu is a PhD student at Lehigh University.">
    <meta name="keywords" content="Yixin Liu,Machine Learning,Computer Vision,Natural Language Processing,AI Safety">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css" integrity="sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB" crossorigin="anonymous">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="shortcut icon" href="static/img/GTVertical_RGB.png">

    <link rel="stylesheet" href="styles.css">
</head>

<body style="background-color: white;">
    

    <div id="main">
    <div class="main-content">
        <div id="main-content-container" class="container">
            <div class="row">
                <div class="col-avatar">
                    <a href="static/image/headpic.jpeg" target="_blank">
                        <img src="static/image/headpic.jpeg" class="avatar" width=150 style="cursor: pointer;" title="Click to view full size" />
                    </a>
                </div>
                <div class="col-sm-12 col-md-9 mx-auto" style="text-align: center;">
                    <div id="main-info-container">
                            <div class="col-name">
                                    <h1 class="name"><span>Yixin Liu </span><span style="font-size: medium;">(刘奕鑫) </span></h1> 
                                    <p class="email" style="margin-top:5px;margin-bottom:10px;">Email: yila22 [AT] lehigh [.] edu | <strong style="color:#c41e3a;">Expected Graduation: May 2026</strong></p>
                                    <p class="text" style="margin-bottom:10px;">4th-year CSE Ph.D. student at Lehigh University (Advisor: <a href="https://lichao-sun.github.io", target="_blank">Prof. Lichao Sun</a>)<br>
                                    Research: Trustworthy ML, Generative AI Safety, Content Protection/Provenance<br>
                                    Industry: Dolby Labs (8 months), Samsung Research America (11 months)<br>
                                    B.E. Software Engineering, South China University of Technology (2022)
                            </div>

                            <div class="col-name">
                            <i style="font-size:24px" class="fa">&#xf1a0;</i>
                            <a href="https://scholar.google.com/citations?user=0GcGHncAAAAJ&hl=en">[Google Scholar]</a>
                            <!-- <a href="https://www.semanticscholar.org/author/Haotian-Xue/30944025">[Semantic Scholar] </a> -->

                            <i style="font-size:24px" class="fa">&#xf09b;</i>
                            <a href="https://github.com/liuyixin-louis">[Github]</a>
                            <!-- https://www.linkedin.com/in/yixin-liu-564b9523b/ -->
                            <i style="font-size:24px" class="fa">&#xf08c;</i>
                            <a href="https://www.linkedin.com/in/yixin-liu-564b9523b/">[LinkedIn]</a>

                    </div>
                    <div id="calendarContainer" style="display: none; position: absolute; left: 0; right: 0; background: white; z-index: 1000; padding: 20px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
                        <iframe src="https://calendar.google.com/calendar/embed?src=yila22%40lehigh.edu&ctz=America%2FLos_Angeles" style="border: 0" width="100%" height="600" frameborder="0" scrolling="no"></iframe>
                    </div>
            </div>
        </div>
    </div>
</div>

<div class="main-content">
    <div class="main-more-container">
        <div class="main-bio-container">
            <h5 class="subtitle">News & Highlights</h5>
            <ul style="line-height: 1.5; margin-top: -5px;">
                <li>
                    <span style="color:#c41e3a; font-weight: bold;">[Seeking Position] </span> I am actively looking for full-time research scientist/engineer positions starting May 2026. My expertise spans LLMs, reinforcement fine-tuning (Group Relative Policy Optimization/GRPO), synthetic content detection, audio language models, AI safety, content protection, watermarking, and trustworthy ML. Please <a href="mailto:yila22@lehigh.edu" style="color:#22b1bb;">reach out</a> if you have opportunities!
                </li>
                <li>
                    <span style="color:#4e613e">[2025.08] </span>  Developed explainable audio synthetic content detection system at Dolby Labs using LLMs with reinforcement learning, achieving better explainability, generalizability, and effectiveness.
                </li>
                <li>
                    <span style="color:#4e613e">[2025.01] </span>  Our <a href="https://liuyixin-louis.github.io/xattnmark/" style="color:#22b1bb;font-weight: normal;"><u>XAttnMark</u></a> is accepted by ICML'25! State-of-the-art neural audio watermarking achieving joint detection and attribution. <a href="https://icml.cc/virtual/2025/poster/43452" style="color:#22b1bb;">[Virtual Poster]</a>
                </li>
                <li>
                    <span style="color:#4e613e">[2024.09] </span>  Started research internship at Dolby Labs, working on audio watermarking and content protection for Universal Music Group.
                </li>
                <li>
                    <span style="color:#4e613e">[2024.07] </span>  Invited Talk at Microsoft ASG Research Day on "Adversarial Perturbation in Personalized Diffusion Models".
                </li>
                <li>
                    <span style="color:#4e613e">[2024.06] </span>  Presented <a href="https://metacloak.github.io" style="color:#22b1bb;font-weight: normal;"><u>MetaCloak</u></a> as CVPR'24 Oral - <a href="https://www.youtube.com/watch?v=-oqm1lHglmk">watch the talk</a>!
                </li>
                <li>
                    <span style="color:#4e613e">[2024.05] </span>  Our <a href="https://arxiv.org/abs/2311.17983v2" style="color:#22b1bb;font-weight: normal;"><u>FViT</u></a> is accepted by ICML'24 as Spotlight!
                </li>
                <li>
                    <span style="color:#4e613e">[2024.05] </span>  Completed internship at Samsung Research America on Graph-based RAG for log analysis.
                </li>
                <li>
                    <span style="color:#4e613e">[2023.12] </span>  Our <a href="https://arxiv.org/abs/2311.13091" style="color:#22b1bb;font-weight: normal;"><u>Stable Unlearnable Example (SEM)</u></a> is accepted by AAAI'24! Achieving 3.91× speedup with improved protection efficacy.
                </li>
            </ul>

            <h5 class="subtitle" style="margin-top:30px">Research Interest</h5>
            <p>
                I am broadly interested in content protection in the era of generative AI and trustworthy ML. 
                My research focuses on the intersection between powerful generative AI and copyright protection, developing data-centric approaches to safeguard user data from unauthorized exploitation and provide robust source verification.
            </p>
            <ul>
                <li><b>Proactive UGC Protection</b> [<a href="https://metacloak.github.io">MetaCloak (CVPR'24 Oral)</a>, <a href="https://arxiv.org/abs/2406.18944">DiffShortcut</a>, <a href="https://arxiv.org/abs/2311.13091">SEM (AAAI'24)</a>, <a href="https://arxiv.org/abs/2311.12066">EditShield (ECCV'24)</a>, <a href="https://arxiv.org/abs/2403.10573">MUE (ICML'24 Workshop)</a>, <a href="https://arxiv.org/abs/2310.07100">GraphCloak</a>, <a href="https://arxiv.org/abs/2410.00878">Linear Solver Analysis</a>]: User-generated content faces unprecedented threats from unauthorized AI training. By exploiting the fundamental vulnerability that neural networks are not robust to small input perturbations, we develop protective mechanisms that prevent unauthorized model training while preserving data utility for legitimate use.</li>

                <li><b>AIGC Watermarking and Detection</b> [<a href="https://liuyixin-louis.github.io/xattnmark/">XAttnMark (ICML'25)</a>, <a href="https://arxiv.org/abs/2305.13257">TextMarker</a>]: As generative models blur the boundary between real and fake content, robust authentication becomes critical. We develop watermarking techniques that enable AI content attribution and source verification across modalities, including state-of-the-art neural audio watermarking with joint detection and attribution capabilities.</li>

                <li><b>Robust Explainable AI</b> [<a href="https://arxiv.org/abs/2211.13290">SEAT (AAAI'23 Oral)</a>, <a href="https://arxiv.org/abs/2311.17983v2">FViTs (ICML'24 Spotlight)</a>]: The exploration of adversarial learning and explainability mechanisms enhances our understanding of model vulnerabilities and interpretability. SEAT addresses attention mechanism instability, providing stable and explainable attention for NLP tasks. FViTs develops faithful vision transformers through denoised diffusion smoothing, ensuring robust attention maps under adversarial attacks. These works advance our understanding of adversarial learning, robustness red-teaming, and robust explainable AI foundations.</li>

                <!-- <li><b>Generative Models + X</b>: utilize/learn strong prior knowledge using <b style="color
                    :green">Generative Models</b> (e.g. Diffusion Models), to solve AI problems, including robust AI, robot learning  and inverse problem</li>
                <li><b>Compositional and Explainable AI</b>: learning <b style="color
                    :green">Compositional</b> and <b style="color
                    :green">Explainable</b> representation, stuctures or solutions for deep learning problems in e.g. Computer Vision and Natural Language Processing</li> -->
                <!-- Safeguarding against Unauthorized Exploitation -->
                
                <!-- learnability manipulation -->
                <!-- <li><b>Learnability Manipulation</b>: study the learnability of models, including the interpretability and generalization of models.</li> -->
                <!-- watermarking and source attribution -->
                <!-- <li><b>Watermarking and Source Attribution</b>: study the watermarking and source attribution of models, including the robustness and generalization of models.</li> -->
                <!-- efficiency in large frontier models -->
                
                <!-- <li><b>AI Safety</b>: i) <b style="color
                    :green">Safeguarding against Unauthorized Exploitation</b>: studying a data-centric approach to safeguarding user's data from unauthorized exploitation (including synthetic content, portrait manipulation, and dataset copyrighting) by degrading trained model's generalization ability; ii) <b style="color
                    :green">Robustness of Explainable AI</b>: study the robustness of explainable AI, including improving the stability and faithfulness of explainable AI tools under adversarial manipulation. 
                </li>
                <li><b>Large-scale Language and Diffusion Model + X </b>: study the large-scale language and diffusion model, including the efficiency and safety of large-scale foundation models. Besides, I am also interested applying those models to solve real-world problems, including vision, NLP and multimodal tasks.
                </li> -->
            </ul>
            <!-- Moreover, I am also interested in explainable AI, focusing on improving the stability and faithfulness of explainable AI tools under adversarial manipulation [<a href="https://arxiv.org/abs/2211.13290">SEAT (AAAI'24)</a>, <a href="https://arxiv.org/abs/2311.17983v2">FViT (ICML'24, Spotlight)</a>].  -->

            <!-- Besides, I am also interested in efficient techniques on training and inference of large-scale language models with limited computational resources.  -->

            <!-- This research aims to enhance the reliability of AI explanations in challenging scenarios. -->
            <!-- <p><b>Robustness of Explainable AI</b>: I study the robustness of explainable AI, focusing on improving the stability and faithfulness of explainable AI tools under adversarial manipulation. This research aims to enhance the reliability of AI explanations in challenging scenarios.</p> -->

           

            <h5 class="subtitle" style="margin-top:30px">Professional Experience</h5>
            <ul>
                <li><b>Dolby Labs</b> - Research Intern (Sep 2024 - Apr 2025, May 2025 - Aug 2025)<br>
                    Working on robust audio watermarking for content protection with Universal Music Group. Developed XAttnMark achieving state-of-the-art detection and attribution performance. Extended work to explainable audio synthetic content detection using LLMs with reinforcement learning (using <a href="https://github.com/volcengine/verl">VERL</a>), focusing on watermark-free scenarios.
                </li>
                <li><b>Samsung Research America</b> - Research Intern (May 2024 - Aug 2024)<br>
                    Developed graph-based RAG system for log analysis, achieving +16 comprehensiveness score improvement. Also worked on DiffShortcut for defending protective perturbations in diffusion models.
                </li>
                <li><b>Samsung Research America</b> - Research Intern (May 2023 - Nov 2023)<br>
                    Proposed efficient defensive perturbation generation methods for data protection against diffusion models, resulting in MetaCloak (CVPR'24 Oral) and GraphCloak for graph data protection.
                </li>
                <li><b>Lehigh University</b> - Teaching Assistant<br>
                    CSE 017 Java Programming (Spring 2023), CSE 007 Python Programming (Spring 2024)
                </li>
            </ul>

            <h5 class="subtitle" style="margin-top:30px">Invited Talks & Presentations</h5>
            <ul>
                <li><b>ICML 2025 Poster</b> - "XAttnMark: Learning Robust Audio Watermarking with Cross-Attention" <a href="https://icml.cc/virtual/2025/poster/43452">[Virtual Poster]</a></li>
                <li><b>Dolby Lab Tech Summit</b> - "Robust Audio Watermarking for the Music Industry" (June 2025) <a href="#">[Slides]</a></li>
                <li><b>Microsoft ASG Research Day</b> - "Adversarial Perturbation in Personalized Diffusion" (invited by Dr. Tianyi Chen, July 2024) <a href="#">[Slides]</a></li>
                <li><b>CVPR 2024 Oral</b> - "MetaCloak: Preventing Unauthorized T2I Diffusion Synthesis" (June 2024) <a href="https://www.youtube.com/watch?v=-oqm1lHglmk">[Video]</a> <a href="#">[Slides]</a></li>
            </ul>

            <h5 class="subtitle" style="margin-top:30px">Reviewer Service</h5> 
            <p style="color:#2271bb">
                NeurIPS'23'24, KDD'23'25, CVPR'24'25, ICML'24'25, ECCV'24 (Outstanding Reviewer), ICLR'25, ICASSP'25, IEEE TIP
            </p> 
            
            
        </div>
    </div>

    <div class="main-more-container">
        <div id="main-pub-container">
            <h5 class="subtitle">Publications
            (
                <a id="publication-by-selected" href="javascript:;", onClick="publicationBySelected();">show selected</a> /
                <a id="publication-by-topic" href="javascript:;", onClick="publicationByTopic();">show all by topic</a> /
                <a id="publication-by-date" href="javascript:;", onClick="publicationByDate();">show all by date</a> 
            )
            </h5>
            <p class="subtitle-aux"><span class="bold">Topics:</span>
                <a href="#topic-unl" onClick="return publicationByTopicSpecific(this)" data-topic="unl">Unauthorized Exploitation</a> /
                <a href="#topic-nlp" onClick="return publicationByTopicSpecific(this)" data-topic="nlp">NLP Safety</a> /
                <a href="#topic-xai" onClick="return publicationByTopicSpecific(this)" data-topic="xai">Explainable AI </a> /
                <a href="#topic-mlc" onClick="return publicationByTopicSpecific(this)" data-topic="mlc">Model Compresssion</a> /
                <a href="#topic-app" onClick="return publicationByTopicSpecific(this)" data-topic="app">Applications</a>

                <span class="note">(*/†: indicates equal contribution.)</span>
            </p>

            <div id="main-pub-card-container" class="activated hide">
                <div class="pub-card" data-topic="nlp" data-year="2025" data-selected="true">
                    <div class="row">
                        <div class="col-l col-xs-12 col-lg-3">
                            <img src="https://liuyixin-louis.github.io/xattnmark/assert/figures/teaser-v1-1.png" width="100%" />
                        </div>
                    <div class="col-r col-xs-12 col-lg-9">
                    <div class="pub-card-body">
                    <h5 class="title">XAttnMark: Learning Robust Audio Watermarking with Cross-Attention</h5>
                    <h6 class="authors">
                    <u>Yixin Liu</u>, Lie Lu, Jihui Jin, Lichao Sun, Andrea Fanelli
                    </h6>
                    <p class="info">
                    <a href="https://liuyixin-louis.github.io/xattnmark/" class="conference" style="color:#0d5797;">[Project Page]</a>
                    <a href="https://arxiv.org/abs/2405.18108" class="conference" style="color:green;">[Paper]</a>
                    <a href="https://icml.cc/virtual/2025/poster/43452" class="conference" style="color:#0d5797;">[ICML Talk]</a>
                    <span class="conference" style="color:green;font-weight:600">ICML 2025</span>
                    </p>
                    </div>
                    </div>
                    </div>
                </div>
                <div class="pub-card" data-topic="unl" data-year="2024" data-selected="true">
                <div class="row">
                    <div class="col-l col-xs-12 col-lg-3">
                        <img src="static/projects/metacloak/metacloak.png" width="100%" />
                    </div>
                <div class="col-r col-xs-12 col-lg-9">
                <div class="pub-card-body">
                <h5 class="title">
                    MetaCloak: Preventing Unauthorized Subject-driven Text-to-image Diffusion-based Synthesis via Meta-learning</h5>
                <h6 class="authors">
                <u>Yixin Liu</u>,
                Chenrui Fan, Yutong Dai, Xun Chen, Pan Zhou, Lichao Sun
                </h6>
                <p class="info">
                <a href="https://arxiv.org/abs/2311.13127" class="conference" style="color:green">[CVPR 2024 Oral]</a>
                </p>
                </div>
                </div>
                </div>
                </div>

                <div class="pub-card" data-topic="unl" data-year="2024" data-selected="false">
                    <div class="row">
                        <div class="col-l col-xs-12 col-lg-3">
                            <img src="static/projects/unl-med/v2.png" width="100%" />
                        </div>
                    <div class="col-r col-xs-12 col-lg-9">
                    <div class="pub-card-body">
                    <h5 class="title">Medical Unlearnable Examples: Securing Medical Data from Unauthorized Traning via Sparsity-Aware Local Masking</h5>
                    <h6 class="authors">
                    Weixiang Sun, <u>Yixin Liu</u>, Zhiling Yan, Kaidi Xu, Lichao Sun
                    </h6>
                    <p class="info">
                        <a href="https://arxiv.org/abs/2311.09127" class="conference" style="color:#4e613e;">[ICML'24 Next Gen AI Safety 2024 Workshop]</a>
                    </p>
                    </div>
                    </div>
                </div>
                </div>
                

                <!-- <div class="pub-card" data-topic="nlp" data-year="2024" data-selected="true">
                    <div class="row">
                        <div class="col-l col-xs-12 col-lg-3">
                            <img src="static/projects/jailbreak-gpt4v/framework.png" width="100%" />
                        </div>
                    <div class="col-r col-xs-12 col-lg-9">
                    <div class="pub-card-body">
                    <h5 class="title">Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts</h5>
                    <h6 class="authors">
                    Yuanwei Wu, Xiang Li, <u>Yixin Liu</u>, Pan Zhou, Lichao Sun
                    </h6>
                    <p class="info">
                    <a href="https://arxiv.org/abs/2311.09127" class="conference" style="color:#0d5797;">[Preprint.]</a>
                    </p>
                    </div>
                    </div>
                    </div>
                    </div> -->
                

                <div class="pub-card" data-topic="unl" data-year="2023" data-selected="true">
                    <div class="row">
                        <div class="col-l col-xs-12 col-lg-3">
                            <img src="static/projects/sem/misalignment.png" width="100%" />
                        </div>
                    <div class="col-r col-xs-12 col-lg-9">
                    <div class="pub-card-body">
                    <h5 class="title">Stable Unlearnable Example: Enhancing the Robustness of Unlearnable Examples via Stable Error-Minimizing Noise</h5>
                    <h6 class="authors">
                    <u>Yixin Liu</u>, Kaidi Xu, Xun Chen, Lichao Sun
                    </h6>
                    <p class="info">
                    <a href="https://arxiv.org/abs/2311.13091" class="conference" style="color:green">[AAAI 2024]</a>
                    </p>
                    </div>
                    </div>
                    </div>
                    </div>    

                
                
                <div class="pub-card" data-topic="xai" data-year="2022" data-selected="true">
                <div class="row"> 
                    <!-- ./projects/fvit/fvit.png -->
                    <div class="col-l col-xs-12 col-lg-3">
                        <img src="static/projects/fvit/framework.jpg" width="100%" />
                    </div>
                <div class="col-r col-xs-12 col-lg-9">
                <div class="pub-card-body">
                <h5 class="title">Improving Faithfulness for Vision Transformers</h5>
                <h6 class="authors">
                Lijie Hu*, <u>Yixin Liu</u>*, Ninghao Liu, Mengdi Huai, Lichao Sun and Di Wang 
                </h6>
                <p class="info">
                <a href="https://arxiv.org/abs/2311.17983v2" class="conference" style="color:green;">[ICML 2024 Spotlight]</a>
                </p>
                </div>
                </div>
                </div>
                </div>
                
                <div class="pub-card" data-topic="unl" data-year="2023" data-selected="true">
                <div class="row">
                    <div class="col-l col-xs-12 col-lg-3">
                        <img src="static/projects/graphcloak/framework.png" width="100%" />
                    </div>
                <div class="col-r col-xs-12 col-lg-9">
                <div class="pub-card-body">
                <h5 class="title">GraphCloak: Safeguarding Graph-structured Data from Unauthorized Exploitation</h5>
                <h6 class="authors">
                <u>Yixin Liu</u>, Chenrui Fan, Xun Chen, Pan Zhou, and Lichao Sun
                </h6>
                <p class="info">
                <a href="https://arxiv.org/abs/2310.07100" class="conference">[Preprint]</a>
                </p>
                </div>
                </div>
                </div>
                </div>
                
                <div class="pub-card" data-topic="nlp" data-year="2023" data-selected="true">
                <div class="row">
                    <div class="col-l col-xs-12 col-lg-3">
                        <img src="static/projects/mia-via-backdoor/framework.png" width="100%" />
                    </div>
                <div class="col-r col-xs-12 col-lg-9">
                <div class="pub-card-body">
                <h5 class="title">Watermarking Classification Dataset for Copyright Protection</h5>
                <h6 class="authors">
                <u>Yixin Liu*</u>, Hongsheng Hu*, Xuyun Zhang, Lichao Sun 
                </h6>
                <p class="info">
                <a href="https://arxiv.org/abs/2305.13257" class="conference">[Preprint]</a>
                </p>
                </div>
                </div>
                </div>
                </div>
                
                <div class="pub-card" data-topic="nlp" data-year="2023" data-selected="true">
                    <div class="row">
                        <!-- ./badgpt/badgpt.jpg -->
                        <div class="col-l col-xs-12 col-lg-3">
                            <img src="static/projects/badgpt/badgpt.jpg" width="100%" />
                        </div>
                    <div class="col-r col-xs-12 col-lg-9">
                    <div class="pub-card-body">
                    <h5 class="title">BadGPT: Exploring Security Vulnerabilities of ChatGPT via Backdoor Attacks to InstructGPT</h5>
                    <h6 class="authors">
                    Jiawen Shi, <u>Yixin Liu</u>, Pan Zhou and Lichao Sun
                    </h6>
                    <p class="info">
                    <a href="https://arxiv.org/abs/2304.12298" class="conference" style="color:green" >[NDSS 2023 Poster]</a>
                    </p>
                    </div>
                    </div>
                    </div>
                    </div>
                
                
                <div class="pub-card" data-topic="unl" data-year="2023" data-selected="true">
                <div class="row">
                    <!-- bio-unl-med.jpg -->
                    <div class="col-l col-xs-12 col-lg-3">
                        <img src="static/projects/unl-med/bio-unl-med.jpg" width="100%" />
                    </div>
                <div class="col-r col-xs-12 col-lg-9">
                <div class="pub-card-body">
                <h5 class="title">Securing Biomedical Images from Unauthorized Training with Anti-Learning Perturbation</h5>
                <h6 class="authors">
                <u>Yixin Liu</u>, Haohui Ye, Lichao Sun
                </h6>
                <p class="info">
                <a href="https://arxiv.org/abs/2303.02559" class="conference" style="color:green" >[NDSS 2023 Poster]</a>
                </p>
                </div>
                </div>
                </div>
                </div>


                <div class="pub-card" data-topic="xai" data-year="2023" data-selected="true">
                    <div class="row">
                        <div class="col-l col-xs-12 col-lg-3">
                            <img src="static/projects/aaai23-seat/teaser.jpg" width="100%" />
                        </div>
                    <div class="col-r col-xs-12 col-lg-9">
                    <div class="pub-card-body">
                    <h5 class="title">SEAT: Stable and Explainable Attention</h5>
                    <h6 class="authors">
                    Lijie Hu*, <u>Yixin Liu</u>*, Ninghao Liu, Mengdi Huai, Lichao Sun and Di Wang 
                    </h6>
                    <p class="info">
                    <a href="https://arxiv.org/abs/2211.13290" class="conference" style="color:green">[Paper]</a>
                    <span class="conference" style="color:green;font-weight:600">AAAI 2023 Oral</span>
                    </p>
                    </div>
                    </div>
                    </div>
                </div>
                
                
                <div class="pub-card" data-topic="mlc" data-year="2021" data-selected="true">
                <div class="row">
                    <!-- ./cacp/framework.jpg -->
                    <div class="col-l col-xs-12 col-lg-3">
                        <img src="static/projects/cacp/framework.jpg" width="100%" />
                    </div>
                <div class="col-r col-xs-12 col-lg-9">
                <div class="pub-card-body">
                <h5 class="title">Conditional Automated Channel Pruning for Deep Neural Networks</h5>
                <h6 class="authors">
                <u>Yixin Liu</u>, Yong Guo, Jiaxin Guo, Luoqian Jiang, Jian Chen
                </h6>
                <p class="info">
                <a href="https://ieeexplore.ieee.org/document/9453104" class="conference" style="color:green" >[IEEE Signal Processing Letters]</a>
                </p>
                </div>
                </div>
                </div>
                </div>


                <div id="main-pub-card-container" class="activated hide">
                    <div class="pub-card" data-topic="mlc" data-year="2022" data-selected="true">
                        <div class="row">
                            <div class="col-l col-xs-12 col-lg-3">
                                <img src="static/projects/meta-prune/poster.png" width="100%" />
                            </div>
                            <div class="col-r col-xs-12 col-lg-9">
                                <div class="pub-card-body">
                                    <h5 class="title">Meta-Pruning with Reinforcement Learning</h5>
                                    <h6 class="authors">
                                        <u>Yixin Liu;</u> Advisor: Jian Chen
                                    </h6>

                                    <p class="info">
                                        <a href="" class="conference" style="color:royalblue"
                                        >[Bachelor Thesis]</a>
                                    </p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>


             <div class="pub-card" data-topic="app" data-year="2021" data-selected="true">
                <div class="row">
                    <div class="col-l col-xs-12 col-lg-3">
                        <img src="static/projects/2021mcm/framework.jpg" width="100%" />
                    </div>
                <div class="col-r col-xs-12 col-lg-9">
                <div class="pub-card-body">
                <h5 class="title">Priority Prediction of Sighting Report Using Machine Learning Methods</h5>
                <h6 class="authors">
                <u>Yixin Liu</u>, Jiaxin Guo, Jieyang Dong, Luoqian Jiang, Haoyuan Ouyang; Advisor: Han Huang
                </h6>
                <p class="info">
                <a href="https://ieeexplore.ieee.org/document/9477549" class="conference" style="color:green" >[IEEE SEAI 2021; Finalist Award in MCM/ICM 2021]</a>
                </p>
                </div>
                </div>
                </div>
                </div>

                

            </div>



            <div id="footer">
                <div class="container">
                    <div class="row">
                        <div class="copyright">
                            &copy; Yixin Liu; Updated: Aug 28, 2025
                        </div>
                        
                    </div>
                </div>
            </div>


            <script src="https://code.jquery.com/jquery-3.1.1.min.js" crossorigin="anonymous"></script>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js"
                        integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js"
                    integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
            <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js"
                    integrity="sha384-vBWWzlZJ8ea9aCX4pEW3rVHjgjt7zpkNpZk+02D9phzyeVkE+jo0ieGizqPLForn" crossorigin="anonymous"></script>
            <script type="text/javascript" src="static/js/jquery.color.min.js"></script>
            <script src="script.js"></script> 


        </div>
    </div>
</div>

</body>
</html>
